{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook: Compounding Yields for Pool Validators (Model Extension 5 - WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Experiment Summary](#Experiment-Summary)\n",
    "* [Experiment Assumptions](#Experiment-Assumptions)\n",
    "* [Experiment Setup](#Experiment-Setup)\n",
    "* [Analysis 1: Extended Time-domain](#Analysis-1:-Extended-Time-domain)\n",
    "* [Analysis 2: Sweep of Pool Size](#Analysis-2:-Sweep-of-Pool-Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Summary \n",
    "\n",
    "Each discrete validator requires a 32 ETH deposit when initialized. A validator's effective balance – the value used to calculate validator rewards – is a maximum of 32 ETH. Any rewards a validator earns above and beyond the 32 ETH requirement do not contribute to their yields until they accrue an additional 32 ETH and create another validator instance. This prevents a solo validator from reinvesting their yields to receive compound interest.\n",
    "\n",
    "On the other hand, stakers that utilise validator pools, on exchanges for example, can compound their returns by pooling the returns of multiple validators to initialize another validator with 32 ETH. The pooling of returns and initialization of a shared validator effectively results in compound interest for those utilising staking pools, potentially resulting in much higher yields, especially over longer periods of time, than that of solo / distributed validators.\n",
    "\n",
    "The following experiment notebook investigates ...\n",
    "\n",
    "\n",
    "# Experiment Assumptions\n",
    "\n",
    "* AVG Pool Size captures the ***initial, average pool size*** accross all pool environments\n",
    "\n",
    "* In order to ensure consistent analysis on the effect of 'average pool size', new validators initialised externally to pools (i.e. from 'validator_process') assemble new pools as oposed to joining existing pools. Consequently, pool sizes grow only when new shared validators are intialized. \n",
    "\n",
    "* Pooling begins simultenously across all pools. Because pool sizes are captured as an average, new shared validator instances are initialised simultaneously across all pools. This leads to sudden 'jumps' in new shared validator instances as pools accrue the target stake ammount at the same time. In reality, such jumps are unlikely to occur due to variations across validator pool environments.\n",
    "\n",
    "* The current implementation assumes all pool validators engage in pool yield compounding. The model could include a parameter accounting for the fraction of validator pools engaging in pool compounding once more data is known.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup\n",
    "\n",
    "We begin with several experiment-notebook-level preparatory setup operations:\n",
    "\n",
    "* Import relevant dependencies\n",
    "* Import relevant experiment templates\n",
    "* Create copies of experiments\n",
    "* Configure and customize experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the setup module:\n",
    "# * sets up the Python path\n",
    "# * runs shared notebook configuration methods, such as loading IPython modules\n",
    "import setup\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import experiments.notebooks.visualizations as visualizations\n",
    "from experiments.run import run\n",
    "from experiments.utils import display_code\n",
    "from model.types import Stage\n",
    "from model.constants import epochs_per_day, epochs_per_week, epochs_per_month\n",
    "from model.state_variables import validator_count_distribution\n",
    "from model.system_parameters import pool_validator_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/disable logging\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import experiment templates\n",
    "import experiments.templates.time_domain_analysis as time_domain_analysis\n",
    "import experiments.templates.pool_size_sweep_analysis as pool_size_sweep_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1: Extended Time-domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Simulate the model over a 10 year period and plot relevent metrics.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = time_domain_analysis.experiment\n",
    "experiment.engine.deepcopy = True \n",
    "simulation_1 = copy.deepcopy(time_domain_analysis.experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration:\n",
    "DELTA_TIME = epochs_per_week  # epochs per timestep \n",
    "\n",
    "SIMULATION_TIME_MONTHS = 10 * 12\n",
    "TIMESTEPS = epochs_per_month * SIMULATION_TIME_MONTHS // DELTA_TIME\n",
    "\n",
    "simulation_1.timesteps = TIMESTEPS\n",
    "\n",
    "normal_adoption = simulation_1.model.params['validator_process'][0](_run=None, _timestep=None)\n",
    "\n",
    "simulation_1.model.params.update({\n",
    "    \"dt\": [DELTA_TIME], # (default: per week)\n",
    "    \"stage\": [Stage.ALL],\n",
    "    \"avg_pool_size\": [1, 10, 100, 1000], # AVG initial pool size\n",
    "    \"eth_price_process\": [lambda _run, _timestep: 3000],\n",
    "    'validator_process': [lambda _run, _timestep: normal_adoption * 1],\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inititial number of pools (derived from 'avg_pool_size' parameter list)\n",
    "\n",
    "avg_pool_size_list = simulation_1.model.params['avg_pool_size']\n",
    "nValidatorEnvironments = len(validator_count_distribution)\n",
    "number_of_pools_list = np.zeros((len(avg_pool_size_list), nValidatorEnvironments))\n",
    "\n",
    "\n",
    "for i in range(len(avg_pool_size_list)): \n",
    "    for y in range(nValidatorEnvironments):\n",
    "        if y in pool_validator_indeces:\n",
    "            number_of_pools_list[i][y] = np.round(validator_count_distribution[y] / avg_pool_size_list[i])\n",
    "\n",
    "    \n",
    "simulation_1.model.params.update({\"number_of_pools\": number_of_pools_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df_1, exceptions = run(simulation_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do:\n",
    "* Create visualization plots in __init__.py\n",
    "* Label all x-axis time as Date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validator Pools Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG Annualized Daily Profit Yields (%) per pool\n",
    "\n",
    "px.line(\n",
    "    df_1,\n",
    "    x='timestamp',\n",
    "    y=['diy_hardware_profit_yields_pct', 'diy_cloud_profit_yields_pct','pool_staas_pool_profit_yields_pct', 'pool_hardware_pool_profit_yields_pct', 'pool_cloud_pool_profit_yields_pct'],\n",
    "    animation_frame='avg_pool_size',\n",
    "    title='AVG Profit Yields (%) per pool'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG Annualized Daily Profit Yields (%) per pool\n",
    "\n",
    "px.line(\n",
    "    df_1,\n",
    "    x='timestamp',\n",
    "    y=['diy_hardware_profit_yields_pct', 'pool_cloud_pool_profit_yields_pct'],\n",
    "    animation_frame='avg_pool_size',\n",
    "    title='AVG Profit Yields (%) per pool'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Profit Yields \n",
    "\n",
    "px.line(\n",
    "    df_1,\n",
    "    x='timestamp',\n",
    "    y=['diy_hardware_cumulative_profit_yields_pct', 'diy_cloud_cumulative_profit_yields_pct', 'pool_staas_pool_cumulative_profit_yields_pct', 'pool_hardware_pool_cumulative_profit_yields_pct', 'pool_cloud_pool_cumulative_profit_yields_pct'],\n",
    "    animation_frame='avg_pool_size',\n",
    "    title='Cumulative Profit Yields (%) per pool'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Profit Yields \n",
    "\n",
    "px.line(\n",
    "    df_1,\n",
    "    x='timestamp',\n",
    "    y=['diy_hardware_cumulative_profit_yields_pct', 'pool_cloud_pool_cumulative_profit_yields_pct'],\n",
    "    animation_frame='avg_pool_size',\n",
    "    title='Cumulative Profit Yields (%) per pool'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Validators per Pool\n",
    "\n",
    "px.line(\n",
    "    df_1,\n",
    "    x='timestamp',\n",
    "    y=['pool_staas_shared_validators_per_pool', 'pool_hardware_shared_validators_per_pool', 'pool_cloud_shared_validators_per_pool'],\n",
    "    animation_frame='avg_pool_size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG ETH STAKED per pool\n",
    "\n",
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_pool_eth_staked', 'pool_hardware_pool_eth_staked', 'pool_cloud_pool_eth_staked'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool size\n",
    "\n",
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_pool_size', 'pool_hardware_pool_size', 'pool_cloud_pool_size'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG Profit (USD) per pool\n",
    "\n",
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_pool_profit', 'pool_hardware_pool_profit', 'pool_cloud_pool_profit'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment-level Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_validator_count', 'pool_hardware_validator_count', 'pool_cloud_validator_count', 'diy_hardware_validator_count', 'diy_cloud_validator_count'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_shared_validators', 'pool_hardware_shared_validators', 'pool_cloud_shared_validators', 'diy_hardware_shared_validators', 'diy_cloud_shared_validators'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ETH Staked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.line(\n",
    "#     df_1,\n",
    "#     x='timestamp',\n",
    "#     y=['pool_staas_eth_staked', 'pool_hardware_eth_staked', 'pool_cloud_eth_staked', 'diy_hardware_eth_staked', 'staas_full_eth_staked'],\n",
    "#     animation_frame='avg_pool_size'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: Sweep of Pool Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase-space analysis showing metrics as a function of the average pool size for pool validators using pool compounding.\n",
    "\n",
    "* In order to accurately account for the compounding of pool validator yeilds over time, we first simulate the model over the desired time-horizon.\n",
    "* Then, we perform a phase-space analysis at the desired timestep (e.g. at year 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis-specific setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the pool-size sweep analysis experiment\n",
    "experiment = pool_size_sweep_analysis.experiment\n",
    "experiment.engine.deepcopy = True \n",
    "# Create a copy of the experiment simulation\n",
    "simulation_2 = copy.deepcopy(experiment.simulations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration \n",
    "\n",
    "# Note: to change the default 'initial AVG pool size' samples, \n",
    "# see 'pool_size_sweep_analysis.py' located in experiments/templates\n",
    "DELTA_TIME = epochs_per_day  # epochs per timestep (determines compounding period)\n",
    "SIMULATION_TIME_MONTHS = 5 * 12  # number of months\n",
    "TIMESTEPS = epochs_per_month * SIMULATION_TIME_MONTHS // DELTA_TIME\n",
    "\n",
    "\n",
    "normal_adoption = simulation_2.model.params['validator_process'][0](_run=None, _timestep=None)\n",
    "\n",
    "simulation_2.model.params.update({\n",
    "    \"dt\": [DELTA_TIME], # determines compounding period (default: per day)\n",
    "    \"validator_process\": [lambda _run, _timestep: normal_adoption * 1], # New validators per epoch\n",
    "    \"stage\": [Stage.ALL], \n",
    "    \"eth_price_process\": [lambda _run, _timestep: 3000],\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "# Set time horizon:\n",
    "YEARS = 5\n",
    "TIMESTEP_ANALYSIS = YEARS * 12 # convert years to months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment execution\n",
    "df_2, exceptions = run(simulation_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do\n",
    "* Set time analysis point in labels / headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot a specific point in time without having to re-run the simulation, \n",
    "# set TIMESTEP_ANALYSIS below and re-run the following cells.\n",
    "\n",
    "YEAR = 3\n",
    "TIMESTEP_ANALYSIS = YEAR * 12  # convert year to month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations.plot_pool_profit_over_pool_size(df_2, TIMESTEP_ANALYSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations.plot_pool_profit_yields_over_pool_size(df_2, TIMESTEP_ANALYSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations.plot_pool_cumulative_yields_over_pool_size(df_2, TIMESTEP_ANALYSIS, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
